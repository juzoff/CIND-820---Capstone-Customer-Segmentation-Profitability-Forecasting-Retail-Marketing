{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "\n",
        "# Specify the encoding as detected ('ascii')\n",
        "train_data = pd.read_csv('/content/srsstat_train_data.csv', encoding='ascii')  # Updated encoding to 'ascii'\n",
        "\n",
        "test_data = pd.read_csv('/content/srsstat_test_data.csv', encoding='ascii')  # Updated encoding to 'ascii'"
      ],
      "metadata": {
        "id": "h0aH8rBMgceH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.value_counts('cluster')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "fIDwARDEpyh0",
        "outputId": "54ef5333-aaf0-4dde-ce1a-9f37cd561ec7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "cluster\n",
              "1    7202\n",
              "0    6913\n",
              "2    6885\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cluster</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6885</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISb8jxewh5hH",
        "outputId": "492c2ea8-0429-44f2-f211-b524c67afb57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 21000 entries, 0 to 20999\n",
            "Data columns (total 87 columns):\n",
            " #   Column                     Non-Null Count  Dtype  \n",
            "---  ------                     --------------  -----  \n",
            " 0   customer_id                21000 non-null  int64  \n",
            " 1   age                        21000 non-null  int64  \n",
            " 2   gender                     21000 non-null  object \n",
            " 3   income_bracket             21000 non-null  object \n",
            " 4   loyalty_program            21000 non-null  object \n",
            " 5   membership_years           21000 non-null  int64  \n",
            " 6   churned                    21000 non-null  object \n",
            " 7   marital_status             21000 non-null  object \n",
            " 8   number_of_children         21000 non-null  int64  \n",
            " 9   education_level            21000 non-null  object \n",
            " 10  occupation                 21000 non-null  object \n",
            " 11  transaction_id             21000 non-null  int64  \n",
            " 12  product_id                 21000 non-null  int64  \n",
            " 13  product_category           21000 non-null  object \n",
            " 14  quantity                   21000 non-null  int64  \n",
            " 15  unit_price                 21000 non-null  float64\n",
            " 16  discount_applied           21000 non-null  float64\n",
            " 17  payment_method             21000 non-null  object \n",
            " 18  store_location             21000 non-null  object \n",
            " 19  transaction_hour           21000 non-null  int64  \n",
            " 20  day_of_week                21000 non-null  object \n",
            " 21  week_of_year               21000 non-null  int64  \n",
            " 22  month_of_year              21000 non-null  int64  \n",
            " 23  avg_purchase_value         21000 non-null  float64\n",
            " 24  purchase_frequency         21000 non-null  object \n",
            " 25  avg_discount_used          21000 non-null  float64\n",
            " 26  preferred_store            21000 non-null  object \n",
            " 27  online_purchases           21000 non-null  int64  \n",
            " 28  in_store_purchases         21000 non-null  int64  \n",
            " 29  avg_items_per_transaction  21000 non-null  float64\n",
            " 30  avg_transaction_value      21000 non-null  float64\n",
            " 31  total_returned_items       21000 non-null  int64  \n",
            " 32  total_returned_value       21000 non-null  float64\n",
            " 33  total_sales_over_lastyear  21000 non-null  float64\n",
            " 34  total_transactions         21000 non-null  int64  \n",
            " 35  total_items_purchased      21000 non-null  int64  \n",
            " 36  total_discounts_received   21000 non-null  float64\n",
            " 37  avg_spent_per_category     21000 non-null  float64\n",
            " 38  max_single_purchase_value  21000 non-null  float64\n",
            " 39  min_single_purchase_value  21000 non-null  float64\n",
            " 40  product_name               21000 non-null  object \n",
            " 41  product_brand              21000 non-null  object \n",
            " 42  product_rating             21000 non-null  float64\n",
            " 43  product_review_count       21000 non-null  int64  \n",
            " 44  product_stock              21000 non-null  int64  \n",
            " 45  product_return_rate        21000 non-null  float64\n",
            " 46  product_size               21000 non-null  object \n",
            " 47  product_weight             21000 non-null  float64\n",
            " 48  product_color              21000 non-null  object \n",
            " 49  product_material           21000 non-null  object \n",
            " 50  product_shelf_life         21000 non-null  int64  \n",
            " 51  promotion_id               21000 non-null  int64  \n",
            " 52  promotion_type             21000 non-null  object \n",
            " 53  promotion_effectiveness    21000 non-null  object \n",
            " 54  promotion_channel          21000 non-null  object \n",
            " 55  promotion_target_audience  21000 non-null  object \n",
            " 56  customer_zip_code          21000 non-null  int64  \n",
            " 57  customer_city              21000 non-null  object \n",
            " 58  customer_state             21000 non-null  object \n",
            " 59  store_zip_code             21000 non-null  int64  \n",
            " 60  store_city                 21000 non-null  object \n",
            " 61  store_state                21000 non-null  object \n",
            " 62  distance_to_store          21000 non-null  float64\n",
            " 63  holiday_season             21000 non-null  object \n",
            " 64  season                     21000 non-null  object \n",
            " 65  weekend                    21000 non-null  object \n",
            " 66  customer_support_calls     21000 non-null  int64  \n",
            " 67  email_subscriptions        21000 non-null  object \n",
            " 68  app_usage                  21000 non-null  object \n",
            " 69  website_visits             21000 non-null  int64  \n",
            " 70  social_media_engagement    21000 non-null  object \n",
            " 71  days_since_last_purchase   21000 non-null  int64  \n",
            " 72  high_value_purchase        21000 non-null  bool   \n",
            " 73  high_value_quantity        21000 non-null  bool   \n",
            " 74  transaction_month          21000 non-null  int64  \n",
            " 75  transaction_year           21000 non-null  int64  \n",
            " 76  product_expiry_date_month  21000 non-null  int64  \n",
            " 77  product_expiry_date_year   21000 non-null  int64  \n",
            " 78  product_manufacture_month  21000 non-null  int64  \n",
            " 79  product_manufacture_year   21000 non-null  int64  \n",
            " 80  promotion_end_month        21000 non-null  int64  \n",
            " 81  promotion_end_year         21000 non-null  int64  \n",
            " 82  last_purchase_month        21000 non-null  int64  \n",
            " 83  last_purchase_year         21000 non-null  int64  \n",
            " 84  promotion_start_month      21000 non-null  int64  \n",
            " 85  promotion_start_year       21000 non-null  int64  \n",
            " 86  cluster                    21000 non-null  int64  \n",
            "dtypes: bool(2), float64(16), int64(37), object(32)\n",
            "memory usage: 13.7+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree - Without Balancing - All Features"
      ],
      "metadata": {
        "id": "x6rnYfmhG6gv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YsU9Z1ydGz_7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e8f150a-6ed6-4355-8dd8-a5c866ddd584"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected features for Decision Tree: ['last_purchase_month', 'promotion_end_month', 'product_manufacture_month', 'month_of_year', 'product_expiry_date_year', 'product_manufacture_year', 'transaction_year', 'product_expiry_date_month', 'transaction_month', 'high_value_purchase', 'week_of_year', 'promotion_start_month', 'day_of_week', 'purchase_frequency', 'customer_city', 'gender', 'weekend', 'store_state', 'email_subscriptions', 'store_location', 'high_value_quantity', 'customer_support_calls', 'product_review_count', 'days_since_last_purchase', 'online_purchases', 'distance_to_store', 'product_rating', 'total_transactions', 'product_weight', 'total_items_purchased', 'unit_price', 'total_returned_value', 'membership_years', 'discount_applied', 'avg_discount_used', 'product_shelf_life', 'total_returned_items', 'transaction_hour', 'min_single_purchase_value', 'number_of_children', 'product_stock', 'avg_purchase_value', 'avg_items_per_transaction', 'website_visits', 'age', 'max_single_purchase_value', 'avg_spent_per_category', 'total_discounts_received', 'product_return_rate', 'avg_transaction_value', 'in_store_purchases']\n",
            "Best Hyperparameters: {'classifier__criterion': 'gini', 'classifier__max_depth': 10, 'classifier__min_samples_leaf': 8, 'classifier__min_samples_split': 2}\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Cluster 0       0.53      0.53      0.53      3019\n",
            "   Cluster 1       0.54      0.54      0.54      3055\n",
            "   Cluster 2       0.53      0.52      0.53      2926\n",
            "\n",
            "    accuracy                           0.53      9000\n",
            "   macro avg       0.53      0.53      0.53      9000\n",
            "weighted avg       0.53      0.53      0.53      9000\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1614  732  673]\n",
            " [ 737 1658  660]\n",
            " [ 710  685 1531]]\n",
            "\n",
            "Accuracy: 0.5337\n",
            "Recall: 0.5337\n",
            "Precision: 0.5337\n",
            "Specificity for Cluster 0: 0.7581\n",
            "Specificity for Cluster 1: 0.7616\n",
            "Specificity for Cluster 2: 0.7805\n",
            "-----------------------------------------------\n",
            "\n",
            "Cross-Validation Results (5-fold):\n",
            "Mean Accuracy: 0.5384\n",
            "Standard Deviation: 0.0066\n",
            "Individual Fold Scores: [0.53933333 0.52683333 0.54616667 0.543      0.5365    ]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score  # Added cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, recall_score, precision_score, confusion_matrix\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Verify train_data and test_data exist from previous steps\n",
        "if 'train_data' not in globals() or 'test_data' not in globals():\n",
        "    raise ValueError(\"train_data or test_data not found! Ensure previous steps are executed.\")\n",
        "\n",
        "# Define the attributes\n",
        "selected_features = [\n",
        "    # Categorical attributes\n",
        "    'last_purchase_month', 'promotion_end_month', 'product_manufacture_month',\n",
        "    'month_of_year', 'product_expiry_date_year', 'product_manufacture_year',\n",
        "    'transaction_year', 'product_expiry_date_month', 'transaction_month',\n",
        "    'high_value_purchase', 'week_of_year', 'promotion_start_month', 'day_of_week',\n",
        "    'purchase_frequency', 'customer_city', 'gender', 'weekend', 'store_state',\n",
        "    'email_subscriptions', 'store_location', 'high_value_quantity',\n",
        "    # Numeric attributes\n",
        "    'customer_support_calls', 'product_review_count', 'days_since_last_purchase',\n",
        "    'online_purchases', 'distance_to_store', 'product_rating', 'total_transactions',\n",
        "    'product_weight', 'total_items_purchased', 'unit_price', 'total_returned_value',\n",
        "    'membership_years', 'discount_applied', 'avg_discount_used', 'product_shelf_life',\n",
        "    'total_returned_items', 'transaction_hour', 'min_single_purchase_value',\n",
        "    'number_of_children', 'product_stock', 'avg_purchase_value',\n",
        "    'avg_items_per_transaction', 'website_visits', 'age', 'max_single_purchase_value',\n",
        "    'avg_spent_per_category', 'total_discounts_received', 'product_return_rate',\n",
        "    'avg_transaction_value', 'in_store_purchases'\n",
        "]\n",
        "\n",
        "# Filter features that exist in train_data\n",
        "selected_features = [col for col in selected_features if col in train_data.columns]\n",
        "print(\"Selected features for Decision Tree:\", selected_features)\n",
        "\n",
        "# Define features (X) and target (y) for train and test sets\n",
        "X_train = train_data[selected_features]\n",
        "y_train = train_data['cluster']\n",
        "X_test = test_data[selected_features]\n",
        "y_test = test_data['cluster']\n",
        "\n",
        "# Identify categorical and numeric columns among selected features\n",
        "categorical_cols = [col for col in selected_features if col in ['last_purchase_month', 'promotion_end_month', 'product_manufacture_month', 'month_of_year', 'product_expiry_date_year',\n",
        "                                                                'product_manufacture_year', 'transaction_year', 'product_expiry_date_month', 'transaction_month', 'high_value_purchase',\n",
        "                                                                'week_of_year', 'promotion_start_month', 'day_of_week', 'purchase_frequency', 'customer_city', 'gender', 'weekend', 'store_state',\n",
        "                                                                'email_subscriptions', 'store_location', 'high_value_quantity']]\n",
        "numeric_cols = [col for col in selected_features if col not in categorical_cols]\n",
        "\n",
        "# Preprocessing pipeline for encoding and scaling\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('num', Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='mean')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ]), numeric_cols),\n",
        "    ('cat', Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "        ('onehot', OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False))\n",
        "    ]), categorical_cols)\n",
        "])\n",
        "\n",
        "# Create pipeline with preprocessing and Decision Tree\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', DecisionTreeClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "# Hyperparameter tuning using GridSearchCV\n",
        "param_grid = {\n",
        "    'classifier__max_depth': [None, 10, 15, 20, 30],\n",
        "    'classifier__min_samples_split': [2, 5, 10, 15],\n",
        "    'classifier__min_samples_leaf': [1, 2, 4, 8],\n",
        "    'classifier__criterion': ['gini']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "print(f\"Best Hyperparameters: {best_params}\")\n",
        "\n",
        "# Train Decision Tree with the best parameters\n",
        "best_model = grid_search.best_estimator_\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions on test set\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Get unique cluster labels for classification report\n",
        "unique_clusters = sorted(y_train.unique())\n",
        "target_names = [f'Cluster {i}' for i in unique_clusters]\n",
        "\n",
        "# Classification Report and Metrics\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Accuracy, Recall, Precision\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Calculate Specificity for each cluster\n",
        "def calculate_specificity(class_idx):\n",
        "    # True Negatives for the current class\n",
        "    tn = cm.sum() - cm[:, class_idx].sum() - cm[class_idx, :].sum() + cm[class_idx, class_idx]\n",
        "    # False Positives for the current class\n",
        "    fp = cm[:, class_idx].sum() - cm[class_idx, class_idx]\n",
        "    # Specificity = TN / (TN + FP)\n",
        "    return tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "\n",
        "# Calculate specificity for each cluster\n",
        "specificity_scores = {f'Cluster {i}': calculate_specificity(idx) for idx, i in enumerate(unique_clusters)}\n",
        "\n",
        "# Print metrics\n",
        "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "for cluster, spec in specificity_scores.items():\n",
        "    print(f\"Specificity for {cluster}: {spec:.4f}\")\n",
        "\n",
        "print(\"-----------------------------------------------\")\n",
        "\n",
        "# --- Cross-Validation on Full Dataset ---\n",
        "# Combine train and test data for cross-validation\n",
        "X_full = pd.concat([X_train, X_test], axis=0)\n",
        "y_full = pd.concat([y_train, y_test], axis=0)\n",
        "\n",
        "# Perform 5-fold cross-validation using the best model\n",
        "cv_scores = cross_val_score(best_model, X_full, y_full, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "print(f\"\\nCross-Validation Results (5-fold):\")\n",
        "print(f\"Mean Accuracy: {cv_scores.mean():.4f}\")\n",
        "print(f\"Standard Deviation: {cv_scores.std():.4f}\")\n",
        "print(f\"Individual Fold Scores: {cv_scores}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree - Without Balancing - Selected Features"
      ],
      "metadata": {
        "id": "jEdZh9TNHG9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.metrics import classification_report, accuracy_score, recall_score, precision_score, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Verify train_data and test_data exist from previous steps\n",
        "if 'train_data' not in globals() or 'test_data' not in globals():\n",
        "    raise ValueError(\"train_data or test_data not found! Ensure previous steps are executed.\")\n",
        "\n",
        "# Define the attributes as specified\n",
        "selected_features = [\n",
        "    # Categorical attributes\n",
        "    'last_purchase_month', 'promotion_end_month', 'product_manufacture_month',\n",
        "    'month_of_year', 'product_expiry_date_year', 'product_manufacture_year',\n",
        "    'transaction_year', 'product_expiry_date_month', 'transaction_month',\n",
        "    'high_value_purchase', 'week_of_year', 'promotion_start_month', 'day_of_week',\n",
        "    'purchase_frequency', 'customer_city', 'gender', 'weekend', 'store_state',\n",
        "    'email_subscriptions', 'store_location', 'high_value_quantity',\n",
        "    # Numeric attributes\n",
        "    'customer_support_calls', 'product_review_count', 'days_since_last_purchase',\n",
        "    'online_purchases', 'distance_to_store', 'product_rating', 'total_transactions',\n",
        "    'product_weight', 'total_items_purchased', 'unit_price', 'total_returned_value',\n",
        "    'membership_years', 'discount_applied', 'avg_discount_used', 'product_shelf_life',\n",
        "    'total_returned_items', 'transaction_hour', 'min_single_purchase_value',\n",
        "    'number_of_children', 'product_stock', 'avg_purchase_value',\n",
        "    'avg_items_per_transaction', 'website_visits', 'age', 'max_single_purchase_value',\n",
        "    'avg_spent_per_category', 'total_discounts_received', 'product_return_rate',\n",
        "    'avg_transaction_value', 'in_store_purchases'\n",
        "]\n",
        "\n",
        "# Filter features that exist in train_data\n",
        "selected_features = [col for col in selected_features if col in train_data.columns]\n",
        "print(\"Initial selected features:\", selected_features)\n",
        "\n",
        "# Define features (X) and target (y) for train and test sets\n",
        "X_train = train_data[selected_features]\n",
        "y_train = train_data['cluster']\n",
        "X_test = test_data[selected_features]\n",
        "y_test = test_data['cluster']\n",
        "\n",
        "# Identify categorical and numeric columns among selected features\n",
        "categorical_cols = [col for col in selected_features if col in ['last_purchase_month', 'promotion_end_month', 'product_manufacture_month', 'month_of_year', 'product_expiry_date_year',\n",
        "                                                                'product_manufacture_year', 'transaction_year', 'product_expiry_date_month', 'transaction_month', 'high_value_purchase',\n",
        "                                                                'week_of_year', 'promotion_start_month', 'day_of_week', 'purchase_frequency', 'customer_city', 'gender', 'weekend', 'store_state',\n",
        "                                                                'email_subscriptions', 'store_location', 'high_value_quantity']]\n",
        "numeric_cols = [col for col in selected_features if col not in categorical_cols]\n",
        "\n",
        "\n",
        "# Preprocessing pipeline for encoding and scaling\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('num', Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='mean')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ]), numeric_cols),\n",
        "    ('cat', Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "        ('onehot', OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False))\n",
        "    ]), categorical_cols)\n",
        "])\n",
        "\n",
        "# Preprocess the data before RFECV to avoid string-to-float issues\n",
        "X_train_transformed = preprocessor.fit_transform(X_train)\n",
        "X_test_transformed = preprocessor.transform(X_test)\n",
        "\n",
        "# Get transformed feature names\n",
        "feature_names = preprocessor.get_feature_names_out()\n",
        "\n",
        "# Initialize RFECV with a simple Decision Tree (no preprocessing needed)\n",
        "rfecv = RFECV(estimator=DecisionTreeClassifier(random_state=42), step=1, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "rfecv.fit(X_train_transformed, y_train)\n",
        "\n",
        "# Get selected features from transformed space\n",
        "selected_mask = rfecv.support_\n",
        "selected_transformed_features = feature_names[selected_mask].tolist()\n",
        "print(f\"Number of Features Selected by RFECV: {len(selected_transformed_features)}\")\n",
        "print(f\"Selected Transformed Features: {selected_transformed_features}\")\n",
        "\n",
        "# Map transformed features back to original features\n",
        "# Since one-hot encoding creates multiple columns per categorical feature, we extract unique original feature names\n",
        "original_selected_features = []\n",
        "for transformed_feature in selected_transformed_features:\n",
        "    # Remove prefixes like 'num__' or 'cat__'\n",
        "    if transformed_feature.startswith('num__'):\n",
        "        original_feature = transformed_feature.replace('num__', '')\n",
        "    elif transformed_feature.startswith('cat__'):\n",
        "        # Extract the original feature name before the category (e.g., 'promotion_effectiveness_Low' -> 'promotion_effectiveness')\n",
        "        original_feature = transformed_feature.replace('cat__', '').split('_')[0]\n",
        "    else:\n",
        "        original_feature = transformed_feature\n",
        "    if original_feature in selected_features and original_feature not in original_selected_features:\n",
        "        original_selected_features.append(original_feature)\n",
        "\n",
        "print(f\"Selected Original Features: {original_selected_features}\")\n",
        "\n",
        "# Use selected original features for training and testing\n",
        "X_train_rfe = X_train[original_selected_features]\n",
        "X_test_rfe = X_test[original_selected_features]\n",
        "\n",
        "# Update categorical and numeric columns for the selected features\n",
        "categorical_cols_rfe = [col for col in original_selected_features if col in categorical_cols]\n",
        "numeric_cols_rfe = [col for col in original_selected_features if col not in categorical_cols]\n",
        "\n",
        "# Update preprocessing pipeline for selected features\n",
        "preprocessor_rfe = ColumnTransformer(transformers=[\n",
        "    ('num', Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='mean')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ]), numeric_cols_rfe),\n",
        "    ('cat', Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "        ('onehot', OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False))\n",
        "    ]), categorical_cols_rfe)\n",
        "])\n",
        "\n",
        "# Create pipeline with preprocessing and Decision Tree\n",
        "pipeline_rfe = Pipeline([\n",
        "    ('preprocessor', preprocessor_rfe),\n",
        "    ('classifier', DecisionTreeClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "# Hyperparameter tuning using GridSearchCV\n",
        "param_grid = {\n",
        "    'classifier__max_depth': [None, 10, 15, 20, 30],\n",
        "    'classifier__min_samples_split': [2, 5, 10, 15],\n",
        "    'classifier__min_samples_leaf': [1, 2, 4, 8],\n",
        "    'classifier__criterion': ['gini']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(pipeline_rfe, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train_rfe, y_train)\n",
        "\n",
        "# Best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "print(f\"Best Hyperparameters: {best_params}\")\n",
        "\n",
        "# Train Decision Tree with the best parameters\n",
        "best_model = grid_search.best_estimator_\n",
        "best_model.fit(X_train_rfe, y_train)\n",
        "\n",
        "# Predictions on test set\n",
        "y_pred = best_model.predict(X_test_rfe)\n",
        "\n",
        "# Get unique cluster labels for classification report\n",
        "unique_clusters = sorted(y_train.unique())\n",
        "target_names = [f'Cluster {i}' for i in unique_clusters]\n",
        "\n",
        "# Classification Report and Metrics\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Accuracy, Recall, Precision\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Calculate Specificity for each cluster\n",
        "def calculate_specificity(class_idx):\n",
        "    # True Negatives for the current class\n",
        "    tn = cm.sum() - cm[:, class_idx].sum() - cm[class_idx, :].sum() + cm[class_idx, class_idx]\n",
        "    # False Positives for the current class\n",
        "    fp = cm[:, class_idx].sum() - cm[class_idx, class_idx]\n",
        "    # Specificity = TN / (TN + FP)\n",
        "    return tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "\n",
        "# Calculate specificity for each cluster\n",
        "specificity_scores = {f'Cluster {i}': calculate_specificity(idx) for idx, i in enumerate(unique_clusters)}\n",
        "\n",
        "# Print metrics\n",
        "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "for cluster, spec in specificity_scores.items():\n",
        "    print(f\"Specificity for {cluster}: {spec:.4f}\")\n",
        "\n",
        "print(\"-----------------------------------------------\")\n",
        "\n",
        "# --- Cross-Validation on Full Dataset ---\n",
        "# Combine train and test data for cross-validation\n",
        "X_full = pd.concat([X_train_rfe, X_test_rfe], axis=0)\n",
        "y_full = pd.concat([y_train, y_test], axis=0)\n",
        "\n",
        "# Perform 5-fold cross-validation using the best model\n",
        "cv_scores = cross_val_score(best_model, X_full, y_full, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "print(f\"\\nCross-Validation Results (5-fold):\")\n",
        "print(f\"Mean Accuracy: {cv_scores.mean():.4f}\")\n",
        "print(f\"Standard Deviation: {cv_scores.std():.4f}\")\n",
        "print(f\"Individual Fold Scores: {cv_scores}\")"
      ],
      "metadata": {
        "id": "L8mlRyiqHGvV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27155472-90b3-4c92-89bc-2516118ba3d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial selected features: ['last_purchase_month', 'promotion_end_month', 'product_manufacture_month', 'month_of_year', 'product_expiry_date_year', 'product_manufacture_year', 'transaction_year', 'product_expiry_date_month', 'transaction_month', 'high_value_purchase', 'week_of_year', 'promotion_start_month', 'day_of_week', 'purchase_frequency', 'customer_city', 'gender', 'weekend', 'store_state', 'email_subscriptions', 'store_location', 'high_value_quantity', 'customer_support_calls', 'product_review_count', 'days_since_last_purchase', 'online_purchases', 'distance_to_store', 'product_rating', 'total_transactions', 'product_weight', 'total_items_purchased', 'unit_price', 'total_returned_value', 'membership_years', 'discount_applied', 'avg_discount_used', 'product_shelf_life', 'total_returned_items', 'transaction_hour', 'min_single_purchase_value', 'number_of_children', 'product_stock', 'avg_purchase_value', 'avg_items_per_transaction', 'website_visits', 'age', 'max_single_purchase_value', 'avg_spent_per_category', 'total_discounts_received', 'product_return_rate', 'avg_transaction_value', 'in_store_purchases']\n",
            "Number of Features Selected by RFECV: 134\n",
            "Selected Transformed Features: ['num__customer_support_calls', 'num__product_review_count', 'num__days_since_last_purchase', 'num__online_purchases', 'num__distance_to_store', 'num__product_rating', 'num__total_transactions', 'num__product_weight', 'num__total_items_purchased', 'num__unit_price', 'num__total_returned_value', 'num__membership_years', 'num__discount_applied', 'num__avg_discount_used', 'num__product_shelf_life', 'num__total_returned_items', 'num__transaction_hour', 'num__min_single_purchase_value', 'num__number_of_children', 'num__product_stock', 'num__avg_purchase_value', 'num__avg_items_per_transaction', 'num__website_visits', 'num__age', 'num__max_single_purchase_value', 'num__avg_spent_per_category', 'num__total_discounts_received', 'num__product_return_rate', 'num__avg_transaction_value', 'num__in_store_purchases', 'cat__last_purchase_month_2', 'cat__last_purchase_month_4', 'cat__last_purchase_month_5', 'cat__last_purchase_month_7', 'cat__last_purchase_month_8', 'cat__last_purchase_month_9', 'cat__last_purchase_month_10', 'cat__last_purchase_month_11', 'cat__last_purchase_month_12', 'cat__promotion_end_month_2', 'cat__promotion_end_month_3', 'cat__promotion_end_month_4', 'cat__promotion_end_month_5', 'cat__promotion_end_month_7', 'cat__promotion_end_month_9', 'cat__promotion_end_month_10', 'cat__promotion_end_month_11', 'cat__promotion_end_month_12', 'cat__product_manufacture_month_2', 'cat__product_manufacture_month_3', 'cat__product_manufacture_month_4', 'cat__product_manufacture_month_5', 'cat__product_manufacture_month_6', 'cat__product_manufacture_month_7', 'cat__product_manufacture_month_8', 'cat__product_manufacture_month_9', 'cat__product_manufacture_month_10', 'cat__product_manufacture_month_11', 'cat__product_manufacture_month_12', 'cat__month_of_year_3', 'cat__month_of_year_4', 'cat__month_of_year_5', 'cat__month_of_year_6', 'cat__month_of_year_7', 'cat__month_of_year_8', 'cat__month_of_year_9', 'cat__month_of_year_10', 'cat__month_of_year_11', 'cat__month_of_year_12', 'cat__product_expiry_date_year_2023', 'cat__product_manufacture_year_2019', 'cat__transaction_year_2021', 'cat__product_expiry_date_month_2', 'cat__product_expiry_date_month_3', 'cat__product_expiry_date_month_4', 'cat__product_expiry_date_month_5', 'cat__product_expiry_date_month_6', 'cat__product_expiry_date_month_7', 'cat__product_expiry_date_month_8', 'cat__product_expiry_date_month_9', 'cat__product_expiry_date_month_10', 'cat__product_expiry_date_month_12', 'cat__transaction_month_2', 'cat__transaction_month_3', 'cat__transaction_month_5', 'cat__transaction_month_6', 'cat__transaction_month_7', 'cat__transaction_month_8', 'cat__transaction_month_11', 'cat__transaction_month_12', 'cat__high_value_purchase_True', 'cat__week_of_year_4', 'cat__week_of_year_5', 'cat__week_of_year_6', 'cat__week_of_year_8', 'cat__week_of_year_9', 'cat__week_of_year_11', 'cat__week_of_year_12', 'cat__week_of_year_16', 'cat__week_of_year_22', 'cat__week_of_year_40', 'cat__week_of_year_42', 'cat__week_of_year_48', 'cat__week_of_year_49', 'cat__week_of_year_50', 'cat__week_of_year_51', 'cat__promotion_start_month_3', 'cat__promotion_start_month_5', 'cat__promotion_start_month_6', 'cat__promotion_start_month_7', 'cat__promotion_start_month_8', 'cat__promotion_start_month_9', 'cat__promotion_start_month_10', 'cat__promotion_start_month_11', 'cat__promotion_start_month_12', 'cat__day_of_week_Saturday', 'cat__day_of_week_Thursday', 'cat__day_of_week_Wednesday', 'cat__purchase_frequency_Monthly', 'cat__purchase_frequency_Weekly', 'cat__purchase_frequency_Yearly', 'cat__customer_city_City B', 'cat__customer_city_City C', 'cat__customer_city_City D', 'cat__gender_Male', 'cat__gender_Other', 'cat__weekend_Yes', 'cat__store_state_State Y', 'cat__store_state_State Z', 'cat__email_subscriptions_Yes', 'cat__store_location_Location B', 'cat__store_location_Location C', 'cat__store_location_Location D', 'cat__high_value_quantity_True']\n",
            "Selected Original Features: ['customer_support_calls', 'product_review_count', 'days_since_last_purchase', 'online_purchases', 'distance_to_store', 'product_rating', 'total_transactions', 'product_weight', 'total_items_purchased', 'unit_price', 'total_returned_value', 'membership_years', 'discount_applied', 'avg_discount_used', 'product_shelf_life', 'total_returned_items', 'transaction_hour', 'min_single_purchase_value', 'number_of_children', 'product_stock', 'avg_purchase_value', 'avg_items_per_transaction', 'website_visits', 'age', 'max_single_purchase_value', 'avg_spent_per_category', 'total_discounts_received', 'product_return_rate', 'avg_transaction_value', 'in_store_purchases', 'gender', 'weekend']\n",
            "Best Hyperparameters: {'classifier__criterion': 'gini', 'classifier__max_depth': 10, 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 15}\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Cluster 0       0.52      0.53      0.53      3019\n",
            "   Cluster 1       0.53      0.53      0.53      3055\n",
            "   Cluster 2       0.53      0.53      0.53      2926\n",
            "\n",
            "    accuracy                           0.53      9000\n",
            "   macro avg       0.53      0.53      0.53      9000\n",
            "weighted avg       0.53      0.53      0.53      9000\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1611  741  667]\n",
            " [ 760 1624  671]\n",
            " [ 701  687 1538]]\n",
            "\n",
            "Accuracy: 0.5303\n",
            "Recall: 0.5303\n",
            "Precision: 0.5304\n",
            "Specificity for Cluster 0: 0.7557\n",
            "Specificity for Cluster 1: 0.7598\n",
            "Specificity for Cluster 2: 0.7797\n",
            "-----------------------------------------------\n",
            "\n",
            "Cross-Validation Results (5-fold):\n",
            "Mean Accuracy: 0.5377\n",
            "Standard Deviation: 0.0026\n",
            "Individual Fold Scores: [0.54033333 0.53316667 0.53983333 0.537      0.53816667]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree - With Balancing - All Features"
      ],
      "metadata": {
        "id": "qc0XIhuzHKGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, recall_score, precision_score, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline as SKPipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import optuna\n",
        "\n",
        "# Verify train_data and test_data exist\n",
        "if 'train_data' not in globals() or 'test_data' not in globals():\n",
        "    raise ValueError(\"train_data or test_data not found! Ensure they are loaded.\")\n",
        "\n",
        "# Define the attributes as specified\n",
        "selected_features = [\n",
        "    # Categorical attributes\n",
        "    'last_purchase_month', 'promotion_end_month', 'product_manufacture_month',\n",
        "    'month_of_year', 'product_expiry_date_year', 'product_manufacture_year',\n",
        "    'transaction_year', 'product_expiry_date_month', 'transaction_month',\n",
        "    'high_value_purchase', 'week_of_year', 'promotion_start_month', 'day_of_week',\n",
        "    'purchase_frequency', 'customer_city', 'gender', 'weekend', 'store_state',\n",
        "    'email_subscriptions', 'store_location', 'high_value_quantity',\n",
        "    # Numeric attributes\n",
        "    'customer_support_calls', 'product_review_count', 'days_since_last_purchase',\n",
        "    'online_purchases', 'distance_to_store', 'product_rating', 'total_transactions',\n",
        "    'product_weight', 'total_items_purchased', 'unit_price', 'total_returned_value',\n",
        "    'membership_years', 'discount_applied', 'avg_discount_used', 'product_shelf_life',\n",
        "    'total_returned_items', 'transaction_hour', 'min_single_purchase_value',\n",
        "    'number_of_children', 'product_stock', 'avg_purchase_value',\n",
        "    'avg_items_per_transaction', 'website_visits', 'age', 'max_single_purchase_value',\n",
        "    'avg_spent_per_category', 'total_discounts_received', 'product_return_rate',\n",
        "    'avg_transaction_value', 'in_store_purchases'\n",
        "]\n",
        "\n",
        "# Filter features that exist in train_data\n",
        "selected_features = [col for col in selected_features if col in train_data.columns]\n",
        "print(\"Initial selected features:\", selected_features)\n",
        "\n",
        "# Use pre-existing train_data and test_data\n",
        "X_train = train_data[selected_features]\n",
        "y_train = train_data['cluster']\n",
        "X_test = test_data[selected_features]\n",
        "y_test = test_data['cluster']\n",
        "\n",
        "# Print class distribution before balancing\n",
        "print(\"Class Distribution Before Balancing (train_data):\", Counter(y_train))\n",
        "print(\"Class Distribution (test_data):\", Counter(y_test))\n",
        "\n",
        "# Identify categorical and numeric columns among selected features\n",
        "categorical_cols = [col for col in selected_features if col in [\n",
        "    'last_purchase_month', 'promotion_end_month', 'product_manufacture_month', 'month_of_year',\n",
        "    'product_expiry_date_year', 'product_manufacture_year', 'transaction_year',\n",
        "    'product_expiry_date_month', 'transaction_month', 'high_value_purchase', 'week_of_year',\n",
        "    'promotion_start_month', 'day_of_week', 'purchase_frequency', 'customer_city', 'gender',\n",
        "    'weekend', 'store_state', 'email_subscriptions', 'store_location', 'high_value_quantity'\n",
        "]]\n",
        "numeric_cols = [col for col in selected_features if col not in categorical_cols]\n",
        "\n",
        "# Preprocessing pipeline for encoding and scaling\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('num', SKPipeline([\n",
        "        ('imputer', SimpleImputer(strategy='mean')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ]), numeric_cols),\n",
        "    ('cat', SKPipeline([\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "        ('onehot', OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False))\n",
        "    ]), categorical_cols)\n",
        "])\n",
        "\n",
        "# Define balancing strategy: target max feasible samples per class\n",
        "class_counts = Counter(y_train)\n",
        "target_samples = min(max(class_counts.values()), 10000)  # Use max class size or 10,000\n",
        "sampling_strategy_under = {k: target_samples for k in class_counts if class_counts[k] > target_samples}\n",
        "sampling_strategy_over = {k: target_samples for k in class_counts}\n",
        "\n",
        "# Print sampling strategies\n",
        "print(\"Undersampling Strategy:\", sampling_strategy_under)\n",
        "print(\"Oversampling Strategy:\", sampling_strategy_over)\n",
        "\n",
        "# Create a pipeline for preprocessing, undersampling, oversampling, and classification\n",
        "pipeline = ImbPipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('undersample', RandomUnderSampler(sampling_strategy=sampling_strategy_under, random_state=42)),\n",
        "    ('oversample', SMOTE(sampling_strategy=sampling_strategy_over, random_state=42)),\n",
        "    ('classifier', DecisionTreeClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "# Define objective function for Optuna\n",
        "def objective(trial):\n",
        "    # Define hyperparameter search space\n",
        "    params = {\n",
        "        'classifier__max_depth': trial.suggest_categorical('classifier__max_depth', [None, 10, 15, 20, 30]),\n",
        "        'classifier__min_samples_split': trial.suggest_int('classifier__min_samples_split', 2, 15),\n",
        "        'classifier__min_samples_leaf': trial.suggest_int('classifier__min_samples_leaf', 1, 8),\n",
        "        'classifier__criterion': trial.suggest_categorical('classifier__criterion', ['gini'])\n",
        "    }\n",
        "\n",
        "    # Set parameters in the pipeline\n",
        "    pipeline.set_params(**params)\n",
        "\n",
        "    # Perform cross-validation\n",
        "    scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "    # Return mean accuracy as the objective to maximize\n",
        "    return scores.mean()\n",
        "\n",
        "# Create Optuna study and optimize\n",
        "study = optuna.create_study(direction='maximize')\n",
        "try:\n",
        "    study.optimize(objective, n_trials=50, timeout=600)  # Run 50 trials or 10 minutes\n",
        "except Exception as e:\n",
        "    print(f\"Optuna optimization failed: {e}\")\n",
        "    print(\"Please check the class distribution and adjust sampling_strategy if necessary.\")\n",
        "    raise\n",
        "\n",
        "# Best hyperparameters\n",
        "best_params = study.best_params\n",
        "print(f\"Best Hyperparameters: {best_params}\")\n",
        "\n",
        "# Set best parameters in the pipeline\n",
        "pipeline.set_params(**best_params)\n",
        "\n",
        "# Train the model with the best parameters\n",
        "try:\n",
        "    pipeline.fit(X_train, y_train)\n",
        "except ValueError as e:\n",
        "    print(f\"Pipeline fitting failed: {e}\")\n",
        "    print(\"Please check the class distribution and adjust sampling_strategy if necessary.\")\n",
        "    raise\n",
        "\n",
        "# Check dataset distribution after balancing\n",
        "X_train_resampled, y_train_resampled = pipeline.named_steps['undersample'].fit_resample(\n",
        "    pipeline.named_steps['preprocessor'].fit_transform(X_train), y_train\n",
        ")\n",
        "X_train_resampled, y_train_resampled = pipeline.named_steps['oversample'].fit_resample(X_train_resampled, y_train_resampled)\n",
        "print(\"After Balancing (Training Data):\", Counter(y_train_resampled))\n",
        "\n",
        "# Get the trained model\n",
        "best_model = pipeline\n",
        "\n",
        "# Predictions on test set\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Get unique cluster labels for classification report\n",
        "unique_clusters = sorted(np.unique(y_train))\n",
        "target_names = [f'Cluster {i}' for i in unique_clusters]\n",
        "\n",
        "# Classification Report and Metrics\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Accuracy, Recall, Precision\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Calculate Specificity for each cluster\n",
        "def calculate_specificity(class_idx):\n",
        "    tn = cm.sum() - cm[:, class_idx].sum() - cm[class_idx, :].sum() + cm[class_idx, class_idx]\n",
        "    fp = cm[:, class_idx].sum() - cm[class_idx, class_idx]\n",
        "    return tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "\n",
        "# Calculate specificity for each cluster\n",
        "specificity_scores = {f'Cluster {i}': calculate_specificity(idx) for idx, i in enumerate(unique_clusters)}\n",
        "\n",
        "# Print metrics\n",
        "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "for cluster, spec in specificity_scores.items():\n",
        "    print(f\"Specificity for {cluster}: {spec:.4f}\")\n",
        "\n",
        "print(\"-----------------------------------------------\")\n",
        "\n",
        "# --- Cross-Validation on Training Data ---\n",
        "cv_scores = cross_val_score(best_model, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "print(f\"\\nCross-Validation Results (5-fold) on Training Data:\")\n",
        "print(f\"Mean Accuracy: {cv_scores.mean():.4f}\")\n",
        "print(f\"Standard Deviation: {cv_scores.std():.4f}\")\n",
        "print(f\"Individual Fold Scores: {cv_scores}\")"
      ],
      "metadata": {
        "id": "83Hnd0LxG-zK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5a5be6b-91f6-4942-d41e-b545ce070824"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-07-22 18:29:50,169] A new study created in memory with name: no-name-8efab890-8cc3-4d43-bb9e-8ce41499d1a5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial selected features: ['last_purchase_month', 'promotion_end_month', 'product_manufacture_month', 'month_of_year', 'product_expiry_date_year', 'product_manufacture_year', 'transaction_year', 'product_expiry_date_month', 'transaction_month', 'high_value_purchase', 'week_of_year', 'promotion_start_month', 'day_of_week', 'purchase_frequency', 'customer_city', 'gender', 'weekend', 'store_state', 'email_subscriptions', 'store_location', 'high_value_quantity', 'customer_support_calls', 'product_review_count', 'days_since_last_purchase', 'online_purchases', 'distance_to_store', 'product_rating', 'total_transactions', 'product_weight', 'total_items_purchased', 'unit_price', 'total_returned_value', 'membership_years', 'discount_applied', 'avg_discount_used', 'product_shelf_life', 'total_returned_items', 'transaction_hour', 'min_single_purchase_value', 'number_of_children', 'product_stock', 'avg_purchase_value', 'avg_items_per_transaction', 'website_visits', 'age', 'max_single_purchase_value', 'avg_spent_per_category', 'total_discounts_received', 'product_return_rate', 'avg_transaction_value', 'in_store_purchases']\n",
            "Class Distribution Before Balancing (train_data): Counter({1: 7202, 0: 6913, 2: 6885})\n",
            "Class Distribution (test_data): Counter({1: 3055, 0: 3019, 2: 2926})\n",
            "Undersampling Strategy: {}\n",
            "Oversampling Strategy: {1: 7202, 2: 7202, 0: 7202}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-07-22 18:30:18,197] Trial 0 finished with value: 0.49485714285714283 and parameters: {'classifier__max_depth': 20, 'classifier__min_samples_split': 9, 'classifier__min_samples_leaf': 1, 'classifier__criterion': 'gini'}. Best is trial 0 with value: 0.49485714285714283.\n",
            "[I 2025-07-22 18:30:32,030] Trial 1 finished with value: 0.5327619047619048 and parameters: {'classifier__max_depth': 10, 'classifier__min_samples_split': 12, 'classifier__min_samples_leaf': 1, 'classifier__criterion': 'gini'}. Best is trial 1 with value: 0.5327619047619048.\n",
            "[I 2025-07-22 18:30:47,588] Trial 2 finished with value: 0.5086666666666668 and parameters: {'classifier__max_depth': None, 'classifier__min_samples_split': 8, 'classifier__min_samples_leaf': 5, 'classifier__criterion': 'gini'}. Best is trial 1 with value: 0.5327619047619048.\n",
            "[I 2025-07-22 18:31:01,334] Trial 3 finished with value: 0.5327142857142857 and parameters: {'classifier__max_depth': 10, 'classifier__min_samples_split': 3, 'classifier__min_samples_leaf': 5, 'classifier__criterion': 'gini'}. Best is trial 1 with value: 0.5327619047619048.\n",
            "[I 2025-07-22 18:31:16,738] Trial 4 finished with value: 0.5064285714285715 and parameters: {'classifier__max_depth': 20, 'classifier__min_samples_split': 15, 'classifier__min_samples_leaf': 3, 'classifier__criterion': 'gini'}. Best is trial 1 with value: 0.5327619047619048.\n",
            "[I 2025-07-22 18:31:32,047] Trial 5 finished with value: 0.5027619047619047 and parameters: {'classifier__max_depth': 15, 'classifier__min_samples_split': 15, 'classifier__min_samples_leaf': 1, 'classifier__criterion': 'gini'}. Best is trial 1 with value: 0.5327619047619048.\n",
            "[I 2025-07-22 18:31:47,497] Trial 6 finished with value: 0.5027619047619047 and parameters: {'classifier__max_depth': 15, 'classifier__min_samples_split': 15, 'classifier__min_samples_leaf': 1, 'classifier__criterion': 'gini'}. Best is trial 1 with value: 0.5327619047619048.\n",
            "[I 2025-07-22 18:32:02,734] Trial 7 finished with value: 0.5174761904761904 and parameters: {'classifier__max_depth': 15, 'classifier__min_samples_split': 2, 'classifier__min_samples_leaf': 6, 'classifier__criterion': 'gini'}. Best is trial 1 with value: 0.5327619047619048.\n",
            "[I 2025-07-22 18:32:16,608] Trial 8 finished with value: 0.5334285714285714 and parameters: {'classifier__max_depth': 10, 'classifier__min_samples_split': 12, 'classifier__min_samples_leaf': 7, 'classifier__criterion': 'gini'}. Best is trial 8 with value: 0.5334285714285714.\n",
            "[I 2025-07-22 18:32:31,316] Trial 9 finished with value: 0.5173333333333333 and parameters: {'classifier__max_depth': 20, 'classifier__min_samples_split': 11, 'classifier__min_samples_leaf': 8, 'classifier__criterion': 'gini'}. Best is trial 8 with value: 0.5334285714285714.\n",
            "[I 2025-07-22 18:32:46,167] Trial 10 finished with value: 0.5173333333333333 and parameters: {'classifier__max_depth': 30, 'classifier__min_samples_split': 6, 'classifier__min_samples_leaf': 8, 'classifier__criterion': 'gini'}. Best is trial 8 with value: 0.5334285714285714.\n",
            "[I 2025-07-22 18:32:59,884] Trial 11 finished with value: 0.5328095238095238 and parameters: {'classifier__max_depth': 10, 'classifier__min_samples_split': 12, 'classifier__min_samples_leaf': 3, 'classifier__criterion': 'gini'}. Best is trial 8 with value: 0.5334285714285714.\n",
            "[I 2025-07-22 18:33:13,453] Trial 12 finished with value: 0.5328095238095238 and parameters: {'classifier__max_depth': 10, 'classifier__min_samples_split': 12, 'classifier__min_samples_leaf': 3, 'classifier__criterion': 'gini'}. Best is trial 8 with value: 0.5334285714285714.\n",
            "[I 2025-07-22 18:33:27,090] Trial 13 finished with value: 0.5320476190476191 and parameters: {'classifier__max_depth': 10, 'classifier__min_samples_split': 10, 'classifier__min_samples_leaf': 3, 'classifier__criterion': 'gini'}. Best is trial 8 with value: 0.5334285714285714.\n",
            "[I 2025-07-22 18:33:40,696] Trial 14 finished with value: 0.5334285714285714 and parameters: {'classifier__max_depth': 10, 'classifier__min_samples_split': 13, 'classifier__min_samples_leaf': 7, 'classifier__criterion': 'gini'}. Best is trial 8 with value: 0.5334285714285714.\n",
            "[I 2025-07-22 18:33:55,692] Trial 15 finished with value: 0.5177619047619048 and parameters: {'classifier__max_depth': 30, 'classifier__min_samples_split': 13, 'classifier__min_samples_leaf': 7, 'classifier__criterion': 'gini'}. Best is trial 8 with value: 0.5334285714285714.\n",
            "[I 2025-07-22 18:34:10,396] Trial 16 finished with value: 0.5177619047619048 and parameters: {'classifier__max_depth': None, 'classifier__min_samples_split': 6, 'classifier__min_samples_leaf': 7, 'classifier__criterion': 'gini'}. Best is trial 8 with value: 0.5334285714285714.\n",
            "[I 2025-07-22 18:34:24,377] Trial 17 finished with value: 0.533952380952381 and parameters: {'classifier__max_depth': 10, 'classifier__min_samples_split': 13, 'classifier__min_samples_leaf': 6, 'classifier__criterion': 'gini'}. Best is trial 17 with value: 0.533952380952381.\n",
            "[I 2025-07-22 18:34:38,143] Trial 18 finished with value: 0.533952380952381 and parameters: {'classifier__max_depth': 10, 'classifier__min_samples_split': 8, 'classifier__min_samples_leaf': 6, 'classifier__criterion': 'gini'}. Best is trial 17 with value: 0.533952380952381.\n",
            "[I 2025-07-22 18:34:51,978] Trial 19 finished with value: 0.533952380952381 and parameters: {'classifier__max_depth': 10, 'classifier__min_samples_split': 7, 'classifier__min_samples_leaf': 6, 'classifier__criterion': 'gini'}. Best is trial 17 with value: 0.533952380952381.\n",
            "[I 2025-07-22 18:35:07,010] Trial 20 finished with value: 0.5067619047619049 and parameters: {'classifier__max_depth': 30, 'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 4, 'classifier__criterion': 'gini'}. Best is trial 17 with value: 0.533952380952381.\n",
            "[I 2025-07-22 18:35:20,957] Trial 21 finished with value: 0.533952380952381 and parameters: {'classifier__max_depth': 10, 'classifier__min_samples_split': 8, 'classifier__min_samples_leaf': 6, 'classifier__criterion': 'gini'}. Best is trial 17 with value: 0.533952380952381.\n",
            "[I 2025-07-22 18:35:34,986] Trial 22 finished with value: 0.533952380952381 and parameters: {'classifier__max_depth': 10, 'classifier__min_samples_split': 7, 'classifier__min_samples_leaf': 6, 'classifier__criterion': 'gini'}. Best is trial 17 with value: 0.533952380952381.\n",
            "[I 2025-07-22 18:35:48,815] Trial 23 finished with value: 0.5327142857142857 and parameters: {'classifier__max_depth': 10, 'classifier__min_samples_split': 9, 'classifier__min_samples_leaf': 5, 'classifier__criterion': 'gini'}. Best is trial 17 with value: 0.533952380952381.\n",
            "[I 2025-07-22 18:36:02,560] Trial 24 finished with value: 0.533952380952381 and parameters: {'classifier__max_depth': 10, 'classifier__min_samples_split': 4, 'classifier__min_samples_leaf': 6, 'classifier__criterion': 'gini'}. Best is trial 17 with value: 0.533952380952381.\n",
            "[I 2025-07-22 18:36:17,659] Trial 25 finished with value: 0.5067619047619049 and parameters: {'classifier__max_depth': None, 'classifier__min_samples_split': 7, 'classifier__min_samples_leaf': 4, 'classifier__criterion': 'gini'}. Best is trial 17 with value: 0.533952380952381.\n",
            "[I 2025-07-22 18:36:31,322] Trial 26 finished with value: 0.533952380952381 and parameters: {'classifier__max_depth': 10, 'classifier__min_samples_split': 10, 'classifier__min_samples_leaf': 6, 'classifier__criterion': 'gini'}. Best is trial 17 with value: 0.533952380952381.\n",
            "[I 2025-07-22 18:36:45,146] Trial 27 finished with value: 0.5327142857142857 and parameters: {'classifier__max_depth': 10, 'classifier__min_samples_split': 7, 'classifier__min_samples_leaf': 5, 'classifier__criterion': 'gini'}. Best is trial 17 with value: 0.533952380952381.\n",
            "[I 2025-07-22 18:36:58,695] Trial 28 finished with value: 0.5342857142857144 and parameters: {'classifier__max_depth': 10, 'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 8, 'classifier__criterion': 'gini'}. Best is trial 28 with value: 0.5342857142857144.\n",
            "[I 2025-07-22 18:37:13,529] Trial 29 finished with value: 0.5173333333333333 and parameters: {'classifier__max_depth': 20, 'classifier__min_samples_split': 4, 'classifier__min_samples_leaf': 8, 'classifier__criterion': 'gini'}. Best is trial 28 with value: 0.5342857142857144.\n",
            "[I 2025-07-22 18:37:27,872] Trial 30 finished with value: 0.520047619047619 and parameters: {'classifier__max_depth': 15, 'classifier__min_samples_split': 9, 'classifier__min_samples_leaf': 8, 'classifier__criterion': 'gini'}. Best is trial 28 with value: 0.5342857142857144.\n",
            "[I 2025-07-22 18:37:41,517] Trial 31 finished with value: 0.5334285714285714 and parameters: {'classifier__max_depth': 10, 'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 7, 'classifier__criterion': 'gini'}. Best is trial 28 with value: 0.5342857142857144.\n",
            "[I 2025-07-22 18:37:55,393] Trial 32 finished with value: 0.533952380952381 and parameters: {'classifier__max_depth': 10, 'classifier__min_samples_split': 6, 'classifier__min_samples_leaf': 6, 'classifier__criterion': 'gini'}. Best is trial 28 with value: 0.5342857142857144.\n",
            "[I 2025-07-22 18:38:09,251] Trial 33 finished with value: 0.5324285714285715 and parameters: {'classifier__max_depth': 10, 'classifier__min_samples_split': 8, 'classifier__min_samples_leaf': 4, 'classifier__criterion': 'gini'}. Best is trial 28 with value: 0.5342857142857144.\n",
            "[I 2025-07-22 18:38:24,356] Trial 34 finished with value: 0.5086666666666668 and parameters: {'classifier__max_depth': None, 'classifier__min_samples_split': 10, 'classifier__min_samples_leaf': 5, 'classifier__criterion': 'gini'}. Best is trial 28 with value: 0.5342857142857144.\n",
            "[I 2025-07-22 18:38:38,176] Trial 35 finished with value: 0.5334285714285714 and parameters: {'classifier__max_depth': 10, 'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 7, 'classifier__criterion': 'gini'}. Best is trial 28 with value: 0.5342857142857144.\n",
            "[I 2025-07-22 18:38:53,219] Trial 36 finished with value: 0.5086666666666668 and parameters: {'classifier__max_depth': 20, 'classifier__min_samples_split': 3, 'classifier__min_samples_leaf': 5, 'classifier__criterion': 'gini'}. Best is trial 28 with value: 0.5342857142857144.\n",
            "[I 2025-07-22 18:39:07,080] Trial 37 finished with value: 0.5324285714285714 and parameters: {'classifier__max_depth': 10, 'classifier__min_samples_split': 8, 'classifier__min_samples_leaf': 2, 'classifier__criterion': 'gini'}. Best is trial 28 with value: 0.5342857142857144.\n",
            "[I 2025-07-22 18:39:21,018] Trial 38 finished with value: 0.534047619047619 and parameters: {'classifier__max_depth': 10, 'classifier__min_samples_split': 14, 'classifier__min_samples_leaf': 6, 'classifier__criterion': 'gini'}. Best is trial 28 with value: 0.5342857142857144.\n",
            "[I 2025-07-22 18:39:35,740] Trial 39 finished with value: 0.5173333333333333 and parameters: {'classifier__max_depth': 30, 'classifier__min_samples_split': 14, 'classifier__min_samples_leaf': 8, 'classifier__criterion': 'gini'}. Best is trial 28 with value: 0.5342857142857144.\n",
            "[I 2025-07-22 18:39:50,417] Trial 40 finished with value: 0.5187619047619048 and parameters: {'classifier__max_depth': 15, 'classifier__min_samples_split': 14, 'classifier__min_samples_leaf': 7, 'classifier__criterion': 'gini'}. Best is trial 28 with value: 0.5342857142857144.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'classifier__max_depth': 10, 'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 8, 'classifier__criterion': 'gini'}\n",
            "After Balancing (Training Data): Counter({0: 7202, 1: 7202, 2: 7202})\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Cluster 0       0.54      0.55      0.54      3019\n",
            "   Cluster 1       0.55      0.54      0.54      3055\n",
            "   Cluster 2       0.54      0.54      0.54      2926\n",
            "\n",
            "    accuracy                           0.54      9000\n",
            "   macro avg       0.54      0.54      0.54      9000\n",
            "weighted avg       0.54      0.54      0.54      9000\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1661  693  665]\n",
            " [ 752 1640  663]\n",
            " [ 690  649 1587]]\n",
            "\n",
            "Accuracy: 0.5431\n",
            "Recall: 0.5431\n",
            "Precision: 0.5432\n",
            "Specificity for Cluster 0: 0.7589\n",
            "Specificity for Cluster 1: 0.7743\n",
            "Specificity for Cluster 2: 0.7814\n",
            "-----------------------------------------------\n",
            "\n",
            "Cross-Validation Results (5-fold) on Training Data:\n",
            "Mean Accuracy: 0.5343\n",
            "Standard Deviation: 0.0056\n",
            "Individual Fold Scores: [0.53380952 0.52690476 0.5352381  0.54404762 0.53142857]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree - With Balancing - Selected Features"
      ],
      "metadata": {
        "id": "cUho4fktHOBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, recall_score, precision_score, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline as SKPipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import optuna\n",
        "\n",
        "# Verify train_data and test_data exist\n",
        "if 'train_data' not in globals() or 'test_data' not in globals():\n",
        "    raise ValueError(\"train_data or test_data not found! Ensure they are loaded.\")\n",
        "\n",
        "# Define the attributes as specified\n",
        "selected_features = [\n",
        "    # Categorical attributes\n",
        "    'last_purchase_month', 'promotion_end_month', 'product_manufacture_month',\n",
        "    'month_of_year', 'product_expiry_date_year', 'product_manufacture_year',\n",
        "    'transaction_year', 'product_expiry_date_month', 'transaction_month',\n",
        "    'high_value_purchase', 'week_of_year', 'promotion_start_month', 'day_of_week',\n",
        "    'purchase_frequency', 'customer_city', 'gender', 'weekend', 'store_state',\n",
        "    'email_subscriptions', 'store_location', 'high_value_quantity',\n",
        "    # Numeric attributes\n",
        "    'customer_support_calls', 'product_review_count', 'days_since_last_purchase',\n",
        "    'online_purchases', 'distance_to_store', 'product_rating', 'total_transactions',\n",
        "    'product_weight', 'total_items_purchased', 'unit_price', 'total_returned_value',\n",
        "    'membership_years', 'discount_applied', 'avg_discount_used', 'product_shelf_life',\n",
        "    'total_returned_items', 'transaction_hour', 'min_single_purchase_value',\n",
        "    'number_of_children', 'product_stock', 'avg_purchase_value',\n",
        "    'avg_items_per_transaction', 'website_visits', 'age', 'max_single_purchase_value',\n",
        "    'avg_spent_per_category', 'total_discounts_received', 'product_return_rate',\n",
        "    'avg_transaction_value', 'in_store_purchases'\n",
        "]\n",
        "\n",
        "# Filter features that exist in train_data\n",
        "selected_features = [col for col in selected_features if col in train_data.columns]\n",
        "print(\"Initial selected features:\", selected_features)\n",
        "\n",
        "# Use pre-existing train_data and test_data (split as in Code 1)\n",
        "X_train = train_data[selected_features]\n",
        "y_train = train_data['cluster']\n",
        "X_test = test_data[selected_features]\n",
        "y_test = test_data['cluster']\n",
        "\n",
        "# Print class distribution before balancing\n",
        "print(\"Class Distribution Before Balancing (train_data):\", Counter(y_train))\n",
        "print(\"Class Distribution (test_data):\", Counter(y_test))\n",
        "\n",
        "# Identify categorical and numeric columns among selected features\n",
        "categorical_cols = [col for col in selected_features if col in [\n",
        "    'last_purchase_month', 'promotion_end_month', 'product_manufacture_month', 'month_of_year',\n",
        "    'product_expiry_date_year', 'product_manufacture_year', 'transaction_year',\n",
        "    'product_expiry_date_month', 'transaction_month', 'high_value_purchase', 'week_of_year',\n",
        "    'promotion_start_month', 'day_of_week', 'purchase_frequency', 'customer_city', 'gender',\n",
        "    'weekend', 'store_state', 'email_subscriptions', 'store_location', 'high_value_quantity'\n",
        "]]\n",
        "numeric_cols = [col for col in selected_features if col not in categorical_cols]\n",
        "\n",
        "# Preprocessing pipeline for encoding and scaling\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('num', SKPipeline([\n",
        "        ('imputer', SimpleImputer(strategy='mean')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ]), numeric_cols),\n",
        "    ('cat', SKPipeline([\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "        ('onehot', OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False))\n",
        "    ]), categorical_cols)\n",
        "])\n",
        "\n",
        "# Define balancing strategy: target max feasible samples per class (from Code 1)\n",
        "class_counts = Counter(y_train)\n",
        "target_samples = min(max(class_counts.values()), 10000)  # Use max class size or 10,000\n",
        "sampling_strategy_under = {k: target_samples for k in class_counts if class_counts[k] > target_samples}\n",
        "sampling_strategy_over = {k: target_samples for k in class_counts}\n",
        "\n",
        "# Print sampling strategies\n",
        "print(\"Undersampling Strategy:\", sampling_strategy_under)\n",
        "print(\"Oversampling Strategy:\", sampling_strategy_over)\n",
        "\n",
        "# Create a pipeline for preprocessing, undersampling, oversampling\n",
        "balancing_pipeline = ImbPipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('undersample', RandomUnderSampler(sampling_strategy=sampling_strategy_under, random_state=42)),\n",
        "    ('oversample', SMOTE(sampling_strategy=sampling_strategy_over, random_state=42))\n",
        "])\n",
        "\n",
        "# Apply balancing to training data\n",
        "X_train_resampled, y_train_resampled = balancing_pipeline.fit_resample(X_train, y_train)\n",
        "print(\"After Balancing (Training Data):\", Counter(y_train_resampled))\n",
        "\n",
        "# Get feature names after preprocessing\n",
        "feature_names = balancing_pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
        "\n",
        "# Train a preliminary Decision Tree to get feature importance\n",
        "preliminary_model = DecisionTreeClassifier(random_state=42)\n",
        "preliminary_model.fit(X_train_resampled, y_train_resampled)\n",
        "feature_importances = preliminary_model.feature_importances_\n",
        "\n",
        "# Define objective function for Optuna\n",
        "def objective(trial):\n",
        "    # Define hyperparameter search space\n",
        "    params = {\n",
        "        'max_depth': trial.suggest_categorical('max_depth', [None, 10, 15, 20, 30]),\n",
        "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 15),\n",
        "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 8),\n",
        "        'criterion': trial.suggest_categorical('criterion', ['gini']),\n",
        "        'n_features': trial.suggest_int('n_features', 1, len(feature_names))\n",
        "    }\n",
        "\n",
        "    # Select top features based on importance\n",
        "    sorted_indices = np.argsort(feature_importances)[::-1]\n",
        "    selected_indices = sorted_indices[:params['n_features']]\n",
        "    X_train_rfe = X_train_resampled[:, selected_indices]\n",
        "\n",
        "    # Train Decision Tree with suggested hyperparameters\n",
        "    classifier = DecisionTreeClassifier(\n",
        "        max_depth=params['max_depth'],\n",
        "        min_samples_split=params['min_samples_split'],\n",
        "        min_samples_leaf=params['min_samples_leaf'],\n",
        "        criterion=params['criterion'],\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Perform cross-validation\n",
        "    scores = cross_val_score(classifier, X_train_rfe, y_train_resampled, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "    # Store selected indices for later use\n",
        "    trial.set_user_attr('selected_indices', selected_indices.tolist())\n",
        "\n",
        "    # Return mean accuracy as the objective to maximize\n",
        "    return scores.mean()\n",
        "\n",
        "# Create Optuna study and optimize\n",
        "study = optuna.create_study(direction='maximize')\n",
        "try:\n",
        "    study.optimize(objective, n_trials=50, timeout=600)  # Run 50 trials or 10 minutes\n",
        "except Exception as e:\n",
        "    print(f\"Optuna optimization failed: {e}\")\n",
        "    print(\"Please check the class distribution and adjust sampling_strategy if necessary.\")\n",
        "    raise\n",
        "\n",
        "# Best hyperparameters and selected features\n",
        "best_params = study.best_params\n",
        "best_trial = study.best_trial\n",
        "selected_indices = best_trial.user_attrs['selected_indices']\n",
        "selected_transformed_features = [feature_names[i] for i in selected_indices]\n",
        "print(f\"Best Hyperparameters: {best_params}\")\n",
        "print(f\"Number of Features Selected: {len(selected_transformed_features)}\")\n",
        "print(f\"Selected Transformed Features: {selected_transformed_features}\")\n",
        "\n",
        "# Map transformed features back to original features\n",
        "original_selected_features = []\n",
        "for transformed_feature in selected_transformed_features:\n",
        "    if transformed_feature.startswith('num__'):\n",
        "        original_feature = transformed_feature.replace('num__', '')\n",
        "    elif transformed_feature.startswith('cat__'):\n",
        "        original_feature = transformed_feature.replace('cat__', '').split('_')[0]\n",
        "    else:\n",
        "        original_feature = transformed_feature\n",
        "    if original_feature in selected_features and original_feature not in original_selected_features:\n",
        "        original_selected_features.append(original_feature)\n",
        "print(f\"Selected Original Features: {original_selected_features}\")\n",
        "\n",
        "# Train final model with best hyperparameters and selected features\n",
        "best_model = DecisionTreeClassifier(\n",
        "    max_depth=best_params['max_depth'],\n",
        "    min_samples_split=best_params['min_samples_split'],\n",
        "    min_samples_leaf=best_params['min_samples_leaf'],\n",
        "    criterion=best_params['criterion'],\n",
        "    random_state=42\n",
        ")\n",
        "X_train_rfe = X_train_resampled[:, selected_indices]\n",
        "best_model.fit(X_train_rfe, y_train_resampled)\n",
        "\n",
        "# Transform test data and select features\n",
        "X_test_transformed = preprocessor.transform(X_test)\n",
        "X_test_rfe = X_test_transformed[:, selected_indices]\n",
        "\n",
        "# Predictions on test set\n",
        "y_pred = best_model.predict(X_test_rfe)\n",
        "\n",
        "# Get unique cluster labels for classification report\n",
        "unique_clusters = sorted(np.unique(y_train))\n",
        "target_names = [f'Cluster {i}' for i in unique_clusters]\n",
        "\n",
        "# Classification Report and Metrics\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=target_names, zero_division=0))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Accuracy, Recall, Precision\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "# Calculate Specificity for each cluster\n",
        "def calculate_specificity(class_idx):\n",
        "    tn = cm.sum() - cm[:, class_idx].sum() - cm[class_idx, :].sum() + cm[class_idx, class_idx]\n",
        "    fp = cm[:, class_idx].sum() - cm[class_idx, class_idx]\n",
        "    return tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "\n",
        "# Calculate specificity for each cluster\n",
        "specificity_scores = {f'Cluster {i}': calculate_specificity(idx) for idx, i in enumerate(unique_clusters)}\n",
        "\n",
        "# Print metrics\n",
        "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "for cluster, spec in specificity_scores.items():\n",
        "    print(f\"Specificity for {cluster}: {spec:.4f}\")\n",
        "\n",
        "print(\"-----------------------------------------------\")\n",
        "\n",
        "# --- Cross-Validation on Training Data ---\n",
        "# Perform 5-fold cross-validation using the best model\n",
        "cv_scores = cross_val_score(best_model, X_train_rfe, y_train_resampled, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "print(f\"\\nCross-Validation Results (5-fold) on Training Data:\")\n",
        "print(f\"Mean Accuracy: {cv_scores.mean():.4f}\")\n",
        "print(f\"Standard Deviation: {cv_scores.std():.4f}\")\n",
        "print(f\"Individual Fold Scores: {cv_scores}\")"
      ],
      "metadata": {
        "id": "CoRJS_BxHQSV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e06878eb-9a8a-47db-ad07-71bacee9f669"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.4.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.16.4)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\n",
            "Initial selected features: ['last_purchase_month', 'promotion_end_month', 'product_manufacture_month', 'month_of_year', 'product_expiry_date_year', 'product_manufacture_year', 'transaction_year', 'product_expiry_date_month', 'transaction_month', 'high_value_purchase', 'week_of_year', 'promotion_start_month', 'day_of_week', 'purchase_frequency', 'customer_city', 'gender', 'weekend', 'store_state', 'email_subscriptions', 'store_location', 'high_value_quantity', 'customer_support_calls', 'product_review_count', 'days_since_last_purchase', 'online_purchases', 'distance_to_store', 'product_rating', 'total_transactions', 'product_weight', 'total_items_purchased', 'unit_price', 'total_returned_value', 'membership_years', 'discount_applied', 'avg_discount_used', 'product_shelf_life', 'total_returned_items', 'transaction_hour', 'min_single_purchase_value', 'number_of_children', 'product_stock', 'avg_purchase_value', 'avg_items_per_transaction', 'website_visits', 'age', 'max_single_purchase_value', 'avg_spent_per_category', 'total_discounts_received', 'product_return_rate', 'avg_transaction_value', 'in_store_purchases']\n",
            "Class Distribution Before Balancing (train_data): Counter({1: 7202, 0: 6913, 2: 6885})\n",
            "Class Distribution (test_data): Counter({1: 3055, 0: 3019, 2: 2926})\n",
            "Undersampling Strategy: {}\n",
            "Oversampling Strategy: {1: 7202, 2: 7202, 0: 7202}\n",
            "After Balancing (Training Data): Counter({0: 7202, 1: 7202, 2: 7202})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-07-22 19:57:35,707] A new study created in memory with name: no-name-d4258316-3ce6-4352-b200-4b0b17e7275b\n",
            "[I 2025-07-22 19:57:42,397] Trial 0 finished with value: 0.5038415426699627 and parameters: {'max_depth': 20, 'min_samples_split': 14, 'min_samples_leaf': 1, 'criterion': 'gini', 'n_features': 127}. Best is trial 0 with value: 0.5038415426699627.\n",
            "[I 2025-07-22 19:57:45,422] Trial 1 finished with value: 0.5121727975072183 and parameters: {'max_depth': 20, 'min_samples_split': 13, 'min_samples_leaf': 3, 'criterion': 'gini', 'n_features': 77}. Best is trial 1 with value: 0.5121727975072183.\n",
            "[I 2025-07-22 19:57:47,880] Trial 2 finished with value: 0.537397047511047 and parameters: {'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 7, 'criterion': 'gini', 'n_features': 98}. Best is trial 2 with value: 0.537397047511047.\n",
            "[I 2025-07-22 19:57:48,690] Trial 3 finished with value: 0.47574726530066724 and parameters: {'max_depth': None, 'min_samples_split': 4, 'min_samples_leaf': 2, 'criterion': 'gini', 'n_features': 7}. Best is trial 2 with value: 0.537397047511047.\n",
            "[I 2025-07-22 19:57:49,027] Trial 4 finished with value: 0.5085168683744926 and parameters: {'max_depth': 10, 'min_samples_split': 15, 'min_samples_leaf': 4, 'criterion': 'gini', 'n_features': 5}. Best is trial 2 with value: 0.537397047511047.\n",
            "[I 2025-07-22 19:57:52,603] Trial 5 finished with value: 0.5077293923405608 and parameters: {'max_depth': None, 'min_samples_split': 12, 'min_samples_leaf': 1, 'criterion': 'gini', 'n_features': 127}. Best is trial 2 with value: 0.537397047511047.\n",
            "[I 2025-07-22 19:57:57,257] Trial 6 finished with value: 0.5141164492554415 and parameters: {'max_depth': 15, 'min_samples_split': 7, 'min_samples_leaf': 4, 'criterion': 'gini', 'n_features': 119}. Best is trial 2 with value: 0.537397047511047.\n",
            "[I 2025-07-22 19:58:00,788] Trial 7 finished with value: 0.5238823643686265 and parameters: {'max_depth': None, 'min_samples_split': 15, 'min_samples_leaf': 7, 'criterion': 'gini', 'n_features': 182}. Best is trial 2 with value: 0.537397047511047.\n",
            "[I 2025-07-22 19:58:03,330] Trial 8 finished with value: 0.5111083040853506 and parameters: {'max_depth': 30, 'min_samples_split': 11, 'min_samples_leaf': 1, 'criterion': 'gini', 'n_features': 28}. Best is trial 2 with value: 0.537397047511047.\n",
            "[I 2025-07-22 19:58:07,487] Trial 9 finished with value: 0.5038879032170835 and parameters: {'max_depth': None, 'min_samples_split': 11, 'min_samples_leaf': 1, 'criterion': 'gini', 'n_features': 152}. Best is trial 2 with value: 0.537397047511047.\n",
            "[I 2025-07-22 19:58:10,485] Trial 10 finished with value: 0.5374895651286438 and parameters: {'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 8, 'criterion': 'gini', 'n_features': 68}. Best is trial 10 with value: 0.5374895651286438.\n",
            "[I 2025-07-22 19:58:12,734] Trial 11 finished with value: 0.5377210144574439 and parameters: {'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 8, 'criterion': 'gini', 'n_features': 66}. Best is trial 11 with value: 0.5377210144574439.\n",
            "[I 2025-07-22 19:58:14,927] Trial 12 finished with value: 0.5371655874729496 and parameters: {'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 8, 'criterion': 'gini', 'n_features': 56}. Best is trial 11 with value: 0.5377210144574439.\n",
            "[I 2025-07-22 19:58:17,112] Trial 13 finished with value: 0.5367029458384796 and parameters: {'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 6, 'criterion': 'gini', 'n_features': 52}. Best is trial 11 with value: 0.5377210144574439.\n",
            "[I 2025-07-22 19:58:19,360] Trial 14 finished with value: 0.5374895651286438 and parameters: {'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 8, 'criterion': 'gini', 'n_features': 68}. Best is trial 11 with value: 0.5377210144574439.\n",
            "[I 2025-07-22 19:58:23,556] Trial 15 finished with value: 0.5210129795609852 and parameters: {'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 6, 'criterion': 'gini', 'n_features': 93}. Best is trial 11 with value: 0.5377210144574439.\n",
            "[I 2025-07-22 19:58:25,931] Trial 16 finished with value: 0.524160120698062 and parameters: {'max_depth': 30, 'min_samples_split': 6, 'min_samples_leaf': 6, 'criterion': 'gini', 'n_features': 34}. Best is trial 11 with value: 0.5377210144574439.\n",
            "[I 2025-07-22 19:58:28,306] Trial 17 finished with value: 0.537489586547238 and parameters: {'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 8, 'criterion': 'gini', 'n_features': 81}. Best is trial 11 with value: 0.5377210144574439.\n",
            "[I 2025-07-22 19:58:30,922] Trial 18 finished with value: 0.534666262426399 and parameters: {'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 5, 'criterion': 'gini', 'n_features': 111}. Best is trial 11 with value: 0.5377210144574439.\n",
            "[I 2025-07-22 19:58:32,942] Trial 19 finished with value: 0.5383228662448418 and parameters: {'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 7, 'criterion': 'gini', 'n_features': 34}. Best is trial 19 with value: 0.5383228662448418.\n",
            "[I 2025-07-22 19:58:36,504] Trial 20 finished with value: 0.5278163282725122 and parameters: {'max_depth': 30, 'min_samples_split': 9, 'min_samples_leaf': 7, 'criterion': 'gini', 'n_features': 34}. Best is trial 19 with value: 0.5383228662448418.\n",
            "[I 2025-07-22 19:58:38,630] Trial 21 finished with value: 0.5371194089838793 and parameters: {'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 8, 'criterion': 'gini', 'n_features': 49}. Best is trial 19 with value: 0.5383228662448418.\n",
            "[I 2025-07-22 19:58:41,007] Trial 22 finished with value: 0.5379988029147708 and parameters: {'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 7, 'criterion': 'gini', 'n_features': 80}. Best is trial 19 with value: 0.5383228662448418.\n",
            "[I 2025-07-22 19:58:42,470] Trial 23 finished with value: 0.5447562408696549 and parameters: {'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 7, 'criterion': 'gini', 'n_features': 21}. Best is trial 23 with value: 0.5447562408696549.\n",
            "[I 2025-07-22 19:58:43,824] Trial 24 finished with value: 0.5427202321432912 and parameters: {'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 5, 'criterion': 'gini', 'n_features': 19}. Best is trial 23 with value: 0.5447562408696549.\n",
            "[I 2025-07-22 19:58:45,339] Trial 25 finished with value: 0.5242989988627798 and parameters: {'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 5, 'criterion': 'gini', 'n_features': 17}. Best is trial 23 with value: 0.5447562408696549.\n",
            "[I 2025-07-22 19:58:47,256] Trial 26 finished with value: 0.5265670887664721 and parameters: {'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 5, 'criterion': 'gini', 'n_features': 19}. Best is trial 23 with value: 0.5447562408696549.\n",
            "[I 2025-07-22 19:58:50,228] Trial 27 finished with value: 0.5377675249347241 and parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 6, 'criterion': 'gini', 'n_features': 42}. Best is trial 23 with value: 0.5447562408696549.\n",
            "[I 2025-07-22 19:58:51,614] Trial 28 finished with value: 0.5428585641338572 and parameters: {'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 4, 'criterion': 'gini', 'n_features': 20}. Best is trial 23 with value: 0.5447562408696549.\n",
            "[I 2025-07-22 19:58:51,763] Trial 29 finished with value: 0.39128041534081104 and parameters: {'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 3, 'criterion': 'gini', 'n_features': 1}. Best is trial 23 with value: 0.5447562408696549.\n",
            "[I 2025-07-22 19:58:53,160] Trial 30 finished with value: 0.5416091639883607 and parameters: {'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 3, 'criterion': 'gini', 'n_features': 19}. Best is trial 23 with value: 0.5447562408696549.\n",
            "[I 2025-07-22 19:58:54,506] Trial 31 finished with value: 0.540915008769308 and parameters: {'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 3, 'criterion': 'gini', 'n_features': 18}. Best is trial 23 with value: 0.5447562408696549.\n",
            "[I 2025-07-22 19:58:56,032] Trial 32 finished with value: 0.5429975172636546 and parameters: {'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 4, 'criterion': 'gini', 'n_features': 22}. Best is trial 23 with value: 0.5447562408696549.\n",
            "[I 2025-07-22 19:58:58,664] Trial 33 finished with value: 0.5149960252443834 and parameters: {'max_depth': 20, 'min_samples_split': 7, 'min_samples_leaf': 4, 'criterion': 'gini', 'n_features': 44}. Best is trial 23 with value: 0.5447562408696549.\n",
            "[I 2025-07-22 19:58:59,538] Trial 34 finished with value: 0.5403130498889392 and parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 2, 'criterion': 'gini', 'n_features': 10}. Best is trial 23 with value: 0.5447562408696549.\n",
            "[I 2025-07-22 19:59:02,426] Trial 35 finished with value: 0.5400354756175544 and parameters: {'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 4, 'criterion': 'gini', 'n_features': 26}. Best is trial 23 with value: 0.5447562408696549.\n",
            "[I 2025-07-22 19:59:02,559] Trial 36 finished with value: 0.4157640531947921 and parameters: {'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 5, 'criterion': 'gini', 'n_features': 1}. Best is trial 23 with value: 0.5447562408696549.\n",
            "[I 2025-07-22 19:59:03,706] Trial 37 finished with value: 0.5254557528791142 and parameters: {'max_depth': 15, 'min_samples_split': 4, 'min_samples_leaf': 4, 'criterion': 'gini', 'n_features': 12}. Best is trial 23 with value: 0.5447562408696549.\n",
            "[I 2025-07-22 19:59:06,580] Trial 38 finished with value: 0.5119874945395971 and parameters: {'max_depth': None, 'min_samples_split': 3, 'min_samples_leaf': 3, 'criterion': 'gini', 'n_features': 59}. Best is trial 23 with value: 0.5447562408696549.\n",
            "[I 2025-07-22 19:59:08,948] Trial 39 finished with value: 0.5142095344657843 and parameters: {'max_depth': 30, 'min_samples_split': 7, 'min_samples_leaf': 4, 'criterion': 'gini', 'n_features': 28}. Best is trial 23 with value: 0.5447562408696549.\n",
            "[I 2025-07-22 19:59:11,040] Trial 40 finished with value: 0.5367955062932649 and parameters: {'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 2, 'criterion': 'gini', 'n_features': 36}. Best is trial 23 with value: 0.5447562408696549.\n",
            "[I 2025-07-22 19:59:12,653] Trial 41 finished with value: 0.5426735181893664 and parameters: {'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 3, 'criterion': 'gini', 'n_features': 22}. Best is trial 23 with value: 0.5447562408696549.\n",
            "[I 2025-07-22 19:59:15,319] Trial 42 finished with value: 0.5409147196182864 and parameters: {'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2, 'criterion': 'gini', 'n_features': 24}. Best is trial 23 with value: 0.5447562408696549.\n",
            "[I 2025-07-22 19:59:18,095] Trial 43 finished with value: 0.5341108782790931 and parameters: {'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 3, 'criterion': 'gini', 'n_features': 146}. Best is trial 23 with value: 0.5447562408696549.\n",
            "[I 2025-07-22 19:59:18,829] Trial 44 finished with value: 0.5382765913720976 and parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 4, 'criterion': 'gini', 'n_features': 9}. Best is trial 23 with value: 0.5447562408696549.\n",
            "[I 2025-07-22 19:59:20,942] Trial 45 finished with value: 0.5341573994656702 and parameters: {'max_depth': 10, 'min_samples_split': 13, 'min_samples_leaf': 5, 'criterion': 'gini', 'n_features': 44}. Best is trial 23 with value: 0.5447562408696549.\n",
            "[I 2025-07-22 19:59:21,873] Trial 46 finished with value: 0.4942610269080728 and parameters: {'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 3, 'criterion': 'gini', 'n_features': 9}. Best is trial 23 with value: 0.5447562408696549.\n",
            "[I 2025-07-22 19:59:24,906] Trial 47 finished with value: 0.5345273735523841 and parameters: {'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 4, 'criterion': 'gini', 'n_features': 176}. Best is trial 23 with value: 0.5447562408696549.\n",
            "[I 2025-07-22 19:59:28,072] Trial 48 finished with value: 0.5219849446559589 and parameters: {'max_depth': 20, 'min_samples_split': 7, 'min_samples_leaf': 5, 'criterion': 'gini', 'n_features': 26}. Best is trial 23 with value: 0.5447562408696549.\n",
            "[I 2025-07-22 19:59:30,858] Trial 49 finished with value: 0.5219387554575917 and parameters: {'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 6, 'criterion': 'gini', 'n_features': 61}. Best is trial 23 with value: 0.5447562408696549.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 7, 'criterion': 'gini', 'n_features': 21}\n",
            "Number of Features Selected: 21\n",
            "Selected Transformed Features: ['num__product_review_count', 'num__days_since_last_purchase', 'num__distance_to_store', 'num__online_purchases', 'num__customer_support_calls', 'num__unit_price', 'num__product_weight', 'num__total_items_purchased', 'num__product_rating', 'num__total_returned_value', 'num__total_transactions', 'num__product_shelf_life', 'num__discount_applied', 'num__avg_items_per_transaction', 'num__avg_discount_used', 'num__min_single_purchase_value', 'num__avg_spent_per_category', 'num__product_stock', 'num__transaction_hour', 'num__membership_years', 'num__avg_purchase_value']\n",
            "Selected Original Features: ['product_review_count', 'days_since_last_purchase', 'distance_to_store', 'online_purchases', 'customer_support_calls', 'unit_price', 'product_weight', 'total_items_purchased', 'product_rating', 'total_returned_value', 'total_transactions', 'product_shelf_life', 'discount_applied', 'avg_items_per_transaction', 'avg_discount_used', 'min_single_purchase_value', 'avg_spent_per_category', 'product_stock', 'transaction_hour', 'membership_years', 'avg_purchase_value']\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Cluster 0       0.54      0.55      0.54      3019\n",
            "   Cluster 1       0.55      0.54      0.54      3055\n",
            "   Cluster 2       0.54      0.54      0.54      2926\n",
            "\n",
            "    accuracy                           0.54      9000\n",
            "   macro avg       0.54      0.54      0.54      9000\n",
            "weighted avg       0.54      0.54      0.54      9000\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1647  685  687]\n",
            " [ 728 1659  668]\n",
            " [ 654  698 1574]]\n",
            "\n",
            "Accuracy: 0.5422\n",
            "Recall: 0.5422\n",
            "Precision: 0.5422\n",
            "Specificity for Cluster 0: 0.7689\n",
            "Specificity for Cluster 1: 0.7674\n",
            "Specificity for Cluster 2: 0.7769\n",
            "-----------------------------------------------\n",
            "\n",
            "Cross-Validation Results (5-fold) on Training Data:\n",
            "Mean Accuracy: 0.5448\n",
            "Standard Deviation: 0.0071\n",
            "Individual Fold Scores: [0.54141601 0.53992131 0.53853275 0.55797269 0.54593844]\n"
          ]
        }
      ]
    }
  ]
}